{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quizmaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import utils\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "def classify_questions():\n",
    "  labels = sorted(\n",
    "      ['science-technology', 'for-kids', 'video-games', 'sports', 'music'])\n",
    "\n",
    "  questions = pd.read_csv(\"data/train_dataset.csv\", header=None,\n",
    "                          encoding=\"iso-8859-1\", sep=\";\",names= ['id', 'question', 'answer', 'topic'])\n",
    "\n",
    "  REPLACE_BY_SPACE = re.compile('[/(){}\\[\\]|@,;]')\n",
    "  BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')\n",
    "  STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "  def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS.sub(' ', text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = ' '.join(word for word in text.split() if\n",
    "                    word not in STOPWORDS)\n",
    "    return text\n",
    "\n",
    "  questions['question'] = questions['question'].apply(clean_text)\n",
    "  X = questions.question\n",
    "  y = questions.topic\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "\n",
    "  # tokenizer\n",
    "  max_words = 2000\n",
    "  tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "  tokenize.fit_on_texts(X_train)\n",
    "  x_train = tokenize.texts_to_matrix(X_train)\n",
    "  x_test = tokenize.texts_to_matrix(X_test)\n",
    "\n",
    "  # Encoder\n",
    "  encoder = LabelEncoder()\n",
    "  encoder.fit(y_train)\n",
    "  y_train = encoder.transform(y_train)\n",
    "  y_test = encoder.transform(y_test)\n",
    "\n",
    "  num_classes = np.max(y_train) + 1\n",
    "  y_train = utils.to_categorical(y_train, num_classes)\n",
    "  y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "  batch_size = 64\n",
    "  epochs = 2\n",
    "\n",
    "  # Build the model\n",
    "  model = Sequential()\n",
    "  model.add(Dense(512, input_shape=(max_words,)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test,y_test))\n",
    "\n",
    "  val_score = model.evaluate(x_train, y_train,\n",
    "                             batch_size=batch_size, verbose=1)\n",
    "  score = model.evaluate(x_test, y_test,\n",
    "                         batch_size=batch_size, verbose=1)\n",
    "  print('Train acc:', val_score[1])\n",
    "  print('Test accuracy:', score[1])\n",
    "\n",
    "  # Classify topics\n",
    "  generated_questions = pd.read_csv(\"data/crowdanswers.tsv\",\n",
    "                                    encoding=\"utf-8\", delimiter=\"\\t\",\n",
    "                                    na_filter=False)\n",
    "  generated_questions.columns = ['id', 'question', 'answer', 'difficulty',\n",
    "                                 'opinion', 'factuality']\n",
    "\n",
    "  tokens = generated_questions['question'].apply(clean_text)\n",
    "\n",
    "  x_predict = tokenize.texts_to_matrix(tokens)\n",
    "  result = model.predict_classes(x_predict, batch_size=1)\n",
    "  predicted_labels = [labels[i] for i in result]\n",
    "  output = pd.DataFrame(data={\"id\": generated_questions[\"id\"],\n",
    "                              \"question\": generated_questions[\"question\"],\n",
    "                              \"answer\": generated_questions[\"answer\"],\n",
    "                              \"difficulty\": generated_questions[\"difficulty\"],\n",
    "                              \"opinion\": generated_questions[\"opinion\"],\n",
    "                              \"factuality\": generated_questions[\"factuality\"],\n",
    "                              \"topic\": predicted_labels})\n",
    "  output.to_csv('data/classified.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7130 samples, validate on 1783 samples\n",
      "Epoch 1/2\n",
      "7130/7130 [==============================] - 3s 396us/step - loss: 0.8346 - acc: 0.7158 - val_loss: 0.4251 - val_acc: 0.8985\n",
      "Epoch 2/2\n",
      "7130/7130 [==============================] - 3s 355us/step - loss: 0.2788 - acc: 0.9272 - val_loss: 0.3049 - val_acc: 0.9108\n",
      "7130/7130 [==============================] - 0s 67us/step\n",
      "1783/1783 [==============================] - 0s 65us/step\n",
      "Train acc: 0.9615708273891647\n",
      "Test accuracy: 0.9108244537036873\n"
     ]
    }
   ],
   "source": [
    "classify_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def get_class_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\", error_bad_lines=False)\n",
    "  questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  questions = questions.groupby(['question', 'topic'], as_index=False)[\n",
    "    'difficulty'].agg(majority)\n",
    "  return questions\n",
    "\n",
    "\n",
    "def get_class_question(difficulty, questions, topic):\n",
    "  return questions[\n",
    "    (questions.topic == topic) & (questions.difficulty == difficulty)]\n",
    "\n",
    "def classification(difficulty, topic):\n",
    "  questions = get_class_questions()\n",
    "  filtered_questions = get_class_question(difficulty, questions, topic)\n",
    "\n",
    "  for index, row in filtered_questions.iterrows():\n",
    "    print(row['question'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 rings' is a song by which American singer?\n",
      "How many strings does a violin have?\n",
      "In 1995, this company released its first console, which went on to dominate the industry.\n",
      "In which European city was Swedish pop group ABBA formed in 1972?\n",
      "This guy had a hit song called Papirsklip - \"Bent Mejding\"? \"Kim Larsen\"? \"Johnny Madsen\"? \"Jarl Friis Mikkelsen\"?'\n",
      "What Michael Jackson song had the first Music video on MTV?\n",
      "What city are the Beatles from?\n",
      "What city hosted the Beatles as the resident band at the Kaiserkeller and Top Ten Club?\n",
      "What instrument is primarily identified with rock and roll?\n",
      "What is Freddie Mercury's (lead singer of Queen) nationality?\n",
      "What is the Best-Selling Albums in History?\n",
      "What is the band containing the famous robotic duo called?\n",
      "What is the famous song called from the movie Titanic? \n",
      "What is the first name of Amadeus Mozart?\n",
      "What is the largest music festival in Budapest, Hungary called?\n",
      "What is the name of Dexter's annoying sister?\n",
      "What is the name of Lady Gaga's first hit single?\n",
      "What is the name of the stadium Queen performed at during Liva Aid?\n",
      "What kind of instrument is a violin?\n",
      "What singer holds the world record for most words in a hit single; Eminem, 50 Cent or Busta Rhymes?\n",
      "What was George Michaels first solo hit called?  \n",
      "What world famous heavy metal band was co-founded by its danish drummer, Lars Ulrich?\n",
      "What's the name of the most famous Italian plumber brothers?\n",
      "When was The Beatles formed?\n",
      "Where is the group abba from?\n",
      "Which American state is known to be a hub for country music?\n",
      "Which album of Linkin Park has the song \"Numb\"?\n",
      "Which country won the 2018 eurovision?\n",
      "Which year did Taylor Swift release the album \"Fearless\"\n",
      "Which year was black ops 1 released\n",
      "Who composed the classical piece Peter and the Wolf?\n",
      "Who is the lead guitarist of Queen?\n",
      "Who is the lead singer of Metallica?\n",
      "Who is the original creator of GIT\n",
      "Who is the writer of the song \"Like a Rolling Stone\"?\n",
      "Who made the album Channel Orange?\n",
      "Who made the song \"Get low\" featured on the soundtrack of the videogame \"Need for Speed: Underground\"? - \"Ludacris\"? \"Lil Wayne\"? \"Lil John\"? \"Nate Dogg\"?' \n",
      "Who wrote the little match girl?\n"
     ]
    }
   ],
   "source": [
    "# Get Questions according to difficulty and topic\n",
    "classification(\"Medium\", \"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence / Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "answers = {\n",
    "  \"for-kids\": {\"false\": 0, \"true\": 0},\n",
    "  \"science-technology\": {\"false\": 0, \"true\": 0},\n",
    "  \"video-games\": {\"false\": 0, \"true\": 0},\n",
    "  \"music\": {\"false\": 0, \"true\": 0},\n",
    "  \"sports\": {\"false\": 0, \"true\": 0},\n",
    "}\n",
    "\n",
    "skipped = []\n",
    "\n",
    "#get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def get_answers():\n",
    "  return answers\n",
    "\n",
    "def get_next_question(g):\n",
    "  return g.sample(n=1, replace=True,\n",
    "           random_state=randint(0, 3000))\n",
    "\n",
    "def calc_threshold(threshold, n):\n",
    "  return np.mean(\n",
    "      [answers[n].get(\"false\"), answers[n].get(\"true\")]) < threshold\n",
    "\n",
    "# use answers from file + answers from classified data,since a few questions missing\n",
    "def give_answer(answer,generated_answer,user_answer,n):\n",
    "  false_answer2 = generated_answer.strip().lower() != user_answer.strip().lower()\n",
    "  false_answer = answer.strip().lower() != user_answer.strip().lower()\n",
    "  if (false_answer & false_answer2):\n",
    "    answers[n][\"false\"] = answers[n].get(\"false\") - 1\n",
    "  else:\n",
    "    answers[n][\"true\"] = answers[n].get(\"true\") + 1\n",
    "\n",
    "def get_conv_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  questions = questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  questions = questions.drop_duplicates(subset='question', keep=\"last\")\n",
    "  return questions.groupby(['topic'])\n",
    "\n",
    "\n",
    "def get_answers_to_questions():\n",
    "  answers_to_questions = pd.read_csv(\"data/question_answer.csv\",\n",
    "                                     encoding=\"utf-8\", sep=\";\")\n",
    "  answers_to_questions.columns = ['question', 'answer']\n",
    "  return answers_to_questions\n",
    "\n",
    "def get_question_answer(answers_to_questions, question):\n",
    "  return answers_to_questions[\n",
    "    answers_to_questions[\"question\"] == question][\n",
    "    \"answer\"].to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def decision(probability=0.9):\n",
    "  return random.random() < probability\n",
    "\n",
    "def polymath_user(probability):\n",
    "  skipped = []\n",
    "  answers_to_questions = get_answers_to_questions()\n",
    "  questions = get_conv_questions()\n",
    "  not_finished = True\n",
    "  amount_of_questions = 0\n",
    "\n",
    "  while not_finished:\n",
    "    for n,g in questions:\n",
    "      if n not in skipped:\n",
    "        if calc_threshold(0, n):\n",
    "          skipped.append(n)\n",
    "          continue\n",
    "        question = get_next_question(g)\n",
    "        answer_generated = question[\"answer\"].to_string(index=False)\n",
    "        question_string = question.to_string(index=False)\n",
    "\n",
    "        answer = get_question_answer(answers_to_questions,question_string)\n",
    "        # hope for the best that the answers are right or available\n",
    "        if len(skipped) <= 4:\n",
    "          amount_of_questions += 1\n",
    "          if decision(probability):\n",
    "            if not answer_generated:\n",
    "              user_answer = answer\n",
    "              give_answer(answer, answer_generated, user_answer, n)\n",
    "            else:\n",
    "              user_answer = answer_generated\n",
    "              give_answer(answer, answer_generated, user_answer, n)\n",
    "          else:\n",
    "            give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        if len(skipped) == 4:\n",
    "          print(\"Amount of questions answered:\", amount_of_questions)\n",
    "          print(\"Finished topic was:\", n)\n",
    "          not_finished = False\n",
    "\n",
    "\n",
    "def topic_expert_user(probability, topic):\n",
    "  skipped = []\n",
    "  answers_to_questions = get_answers_to_questions()\n",
    "  questions = get_conv_questions()\n",
    "  not_finished = True\n",
    "  amount_of_questions = 0\n",
    "\n",
    "  while not_finished:\n",
    "    for n,g in questions:\n",
    "      if n not in skipped:\n",
    "        if calc_threshold(-1, n):\n",
    "          skipped.append(n)\n",
    "          continue\n",
    "        question = get_next_question(g)\n",
    "        answer_generated = question[\"answer\"].to_string(index=False)\n",
    "        question_string = question.to_string(index=False)\n",
    "\n",
    "        answer = get_question_answer(answers_to_questions,question_string)\n",
    "        # hope for the best that the answers are right or available\n",
    "        if n == topic:\n",
    "          if len(skipped) <= 4:\n",
    "            if decision(probability):\n",
    "              amount_of_questions +=1\n",
    "              if not answer_generated:\n",
    "                user_answer = answer\n",
    "                give_answer(answer, answer_generated, user_answer, n)\n",
    "              else:\n",
    "                user_answer = answer_generated\n",
    "                give_answer(answer, answer_generated, user_answer, n)\n",
    "            else:\n",
    "              give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        else:\n",
    "          give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        if len(skipped) == 4:\n",
    "          print(\"Amount of questions answered:\", amount_of_questions)\n",
    "          print(\"Finished Topic was:\", n)\n",
    "          not_finished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of questions answered: 7\n",
      "Finished topic was: for-kids\n",
      "Amount of questions answered: 6\n",
      "Finished Topic was: music\n"
     ]
    }
   ],
   "source": [
    "## Can end up running quite long according to probabilty of answering questions right\n",
    "polymath_user(0.5)\n",
    "topic_expert_user(0.8, \"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friend Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def takeCorrelation(elem):\n",
    "  return elem[1]\n",
    "\n",
    "STEMMER = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def get_friends_questions():\n",
    "  return pd.read_csv(\"data/classified.csv\",\n",
    "                     encoding=\"utf-8\", sep=\",\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer=STEMMER):\n",
    "  return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  return stem_tokens(tokens)\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "  return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "\n",
    "def get_recommendations_feature(cutoff_k, questions, user_id):\n",
    "  print(\"Feature based recommendation\")\n",
    "  tfidf = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\n",
    "  tfs = tfidf.fit_transform(questions['question'])\n",
    "  # add column for vector\n",
    "  questions['tfsvector'] = list(tfs.toarray())\n",
    "  user_features = questions[questions['id'] == int(user_id)]['tfsvector'].mean()\n",
    "  # the questions which a user likes\n",
    "  questions = questions.groupby(['id'])\n",
    "  friends_questions = []\n",
    "  for n, g in questions:\n",
    "    g = g[g['opinion'] > 1]['tfsvector'].mean()\n",
    "    friends_questions.append((n, euclidean_distance(user_features, g)))\n",
    "  friends_questions.sort(key=takeCorrelation, reverse=True)\n",
    "  for friend in friends_questions[:int(cutoff_k)]:\n",
    "    print(friend)\n",
    "\n",
    "\n",
    "def get_recommendations_topic(cutoff_k, questions, user_id):\n",
    "  friends = []\n",
    "  print(\"Topic based recommendation:\")\n",
    "  user_features = questions[questions['id'] == int(user_id)].groupby(['topic'])[\n",
    "    'opinion'].mean()\n",
    "  questions = questions.groupby(['id'])\n",
    "  for n, g in questions:\n",
    "    if n == int(user_id):\n",
    "      continue\n",
    "    # when classification not works properly then some users have only 4 topics\n",
    "    if len(g.groupby(['topic'])['opinion'].mean()) < 5:\n",
    "      continue\n",
    "    corr, p_value = pearsonr(user_features,\n",
    "                             g.groupby(['topic'])['opinion'].mean())\n",
    "    friends.append((n, corr))\n",
    "  friends.sort(key=takeCorrelation, reverse=True)\n",
    "  for friend in friends[:int(cutoff_k)]:\n",
    "    print(friend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature based recommendation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0.36076689057979405)\n",
      "(11, 0.3386440771631049)\n",
      "(27, 0.3282917165082846)\n",
      "(24, 0.30563175815672294)\n",
      "(31, 0.297454486813683)\n"
     ]
    }
   ],
   "source": [
    "# cutoff, questions, user_id\n",
    "get_recommendations_feature(5,get_friends_questions(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic based recommendation:\n",
      "(14, 0.8523846388095632)\n",
      "(17, 0.7238350876608391)\n",
      "(25, 0.6430656727237043)\n",
      "(32, 0.6211709875985529)\n",
      "(34, 0.5381963301021485)\n"
     ]
    }
   ],
   "source": [
    "# cutoff, questions, user_id\n",
    "get_recommendations_topic(5,get_friends_questions(),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  return questions\n",
    "\n",
    "def get_preferance_id(questions, userid):\n",
    "  user_questions = questions[questions['id'] == int(userid)]\n",
    "  return user_questions\n",
    "\n",
    "\n",
    "def get_prefereance_filtered_qustions(questions, user_preferance):\n",
    "  questions = questions[questions['topic'] == user_preferance].head(10)\n",
    "  return questions\n",
    "\n",
    "\n",
    "def get_user_preferance(user_questions):\n",
    "  user_questions = user_questions.groupby('topic')['opinion'].mean()\n",
    "  user_preferance = user_questions.idxmax()\n",
    "  return user_preferance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>opinion</th>\n",
       "      <th>factuality</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Who invented the light bulb?</td>\n",
       "      <td>Thomas Edison</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Who is the only woman to have ever received tw...</td>\n",
       "      <td>Marie Curie</td>\n",
       "      <td>Hard</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>What's the most expensive material on Earth?</td>\n",
       "      <td>dont know</td>\n",
       "      <td>Hard</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Who lives in a pineapple under the sea?</td>\n",
       "      <td>Spongebob Squarepants</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>What's the name of the reindeer in Frozen?</td>\n",
       "      <td>Sven</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the top color in a rainbow?</td>\n",
       "      <td>red</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>In what year was Space Invaders released?</td>\n",
       "      <td>1978</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>What is Linux's creator's full name?</td>\n",
       "      <td>Linus Torvalds</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Which country in the world has maximum number ...</td>\n",
       "      <td>Korea</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>A type glass that is highly resistant to heat?</td>\n",
       "      <td>Heat resistant glass</td>\n",
       "      <td>Hard</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>science-technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question  \\\n",
       "0    0                       Who invented the light bulb?   \n",
       "1    0  Who is the only woman to have ever received tw...   \n",
       "2    0       What's the most expensive material on Earth?   \n",
       "6    0            Who lives in a pineapple under the sea?   \n",
       "7    0         What's the name of the reindeer in Frozen?   \n",
       "8    0               What is the top color in a rainbow?    \n",
       "14   0          In what year was Space Invaders released?   \n",
       "15   0               What is Linux's creator's full name?   \n",
       "16   0  Which country in the world has maximum number ...   \n",
       "17   0     A type glass that is highly resistant to heat?   \n",
       "\n",
       "                   answer difficulty  opinion  factuality               topic  \n",
       "0           Thomas Edison     Medium        2           0  science-technology  \n",
       "1             Marie Curie       Hard        2           0  science-technology  \n",
       "2               dont know       Hard        2           0  science-technology  \n",
       "6   Spongebob Squarepants       Easy        3           0  science-technology  \n",
       "7                    Sven     Medium        3           0  science-technology  \n",
       "8                     red       Hard        3           0  science-technology  \n",
       "14                   1978       Hard        3           0  science-technology  \n",
       "15         Linus Torvalds     Medium        3           0  science-technology  \n",
       "16                  Korea       Hard        1           0  science-technology  \n",
       "17   Heat resistant glass       Hard        1           1  science-technology  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get favourite Topic according to user_id\n",
    "user_questions = get_preferance_id(get_users_questions(),5)\n",
    "user_preferance = get_user_preferance(user_questions)\n",
    "get_prefereance_filtered_qustions(get_users_questions(),user_preferance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulty / Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answered = {\"Easy\": False, \"Medium\": False, \"Hard\": False}\n",
    "\n",
    "# get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def prepare_diff():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  answers_to_questions = pd.read_csv(\"data/question_answer.csv\",\n",
    "                                     encoding=\"utf-8\", sep=\";\")\n",
    "  answers_to_questions.columns = ['question', 'answer']\n",
    "  questions = questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  grouped_questions = questions.groupby(['question', 'topic'], as_index=False)[\n",
    "    'difficulty'].agg(majority)\n",
    "  questions = questions.drop_duplicates(subset='question', keep=\"last\")\n",
    "  return answers_to_questions, grouped_questions, questions\n",
    "\n",
    "\n",
    "def sample_question(questions_to_answer):\n",
    "  return questions_to_answer.sample(n=1, replace=True,\n",
    "                                    random_state=randint(0, 10000))\n",
    "\n",
    "\n",
    "def check_answer(answer, answered, generated_answer, user_answer):\n",
    "  true_answer2 = generated_answer.strip().lower() == user_answer.strip().lower()\n",
    "  true_answer = answer.strip().lower() == user_answer.strip().lower()\n",
    "  if (true_answer) or (true_answer2):\n",
    "    if answered[\"Medium\"] == True:\n",
    "      answered[\"Hard\"] = True\n",
    "    if answered[\"Easy\"] == True:\n",
    "      answered[\"Medium\"] = True\n",
    "    if answered[\"Easy\"] == False:\n",
    "      answered[\"Easy\"] = True\n",
    "\n",
    "\n",
    "def get_answers_to_questions_diff(answers_to_questions, question):\n",
    "  return answers_to_questions[\n",
    "    answers_to_questions[\"question\"] == question][\n",
    "    \"answer\"].to_string(index=False)\n",
    "\n",
    "\n",
    "def get_answered_diff():\n",
    "  return answered\n",
    "\n",
    "\n",
    "def get_questions_to_answer(answered, questions):\n",
    "  questions_to_answer = questions[questions['difficulty'] == \"Easy\"]\n",
    "  if answered[\"Easy\"] == True:\n",
    "    questions_to_answer = questions[questions['difficulty'] == \"Medium\"]\n",
    "  if answered[\"Medium\"] == True:\n",
    "    questions_to_answer = questions[questions['difficulty'] == \"Hard\"]\n",
    "  return questions_to_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuculty_user(probability):\n",
    "  answers_to_questions, grouped_questions, questions = prepare_diff()\n",
    "\n",
    "  answered = get_answered_diff()\n",
    "\n",
    "  not_finished = True\n",
    "\n",
    "  while not_finished:\n",
    "    questions_to_answer = get_questions_to_answer(answered, grouped_questions)\n",
    "\n",
    "    random_topic_question = sample_question(questions_to_answer)\n",
    "\n",
    "    print(\"Difficulty:\", random_topic_question[\"difficulty\"].to_string(index=False))\n",
    "    question = random_topic_question[\"question\"].to_string(index=False)\n",
    "\n",
    "\n",
    "    generated_answer = questions[questions['question'] == question]['answer'].to_string(index=False)\n",
    "\n",
    "    answer = get_answers_to_questions_diff(answers_to_questions, question)\n",
    "\n",
    "    print(question)\n",
    "    if decision(probability):\n",
    "      if not generated_answer:\n",
    "        user_answer = answer\n",
    "        check_answer(answer, answered, generated_answer, user_answer)\n",
    "      else:\n",
    "        user_answer = generated_answer\n",
    "        check_answer(answer, answered, generated_answer, user_answer)\n",
    "    else:\n",
    "      check_answer(answer, answered, generated_answer, \"Wrong!!!\")\n",
    "    answered = get_answered_diff()\n",
    "    if answered[\"Hard\"] == True:\n",
    "      print(\"Finished arrived at hard questions\")\n",
    "      not_finished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty: Easy\n",
      "When was a first iPhone released?\n",
      "Difficulty: Easy\n",
      "What game is known for stealing cars and beati...\n",
      "Difficulty: Easy\n",
      "What does VR stand for?\n",
      "Difficulty: Medium\n",
      "How many grand slams has Roger Federer won\n",
      "Difficulty: Hard\n",
      "What is the name of the best standard FIDE ran...\n",
      "Difficulty: Hard\n",
      "Which of these is the oldest fully-animated Di...\n",
      "Difficulty: Hard\n",
      "What was the debut album of Daft Punk called?\n",
      "Difficulty: Hard\n",
      "Who performed the hit Baker Street?\n",
      "Finished arrived at hard questions\n"
     ]
    }
   ],
   "source": [
    "# Probability of answering a question right\n",
    "diffuculty_user(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
