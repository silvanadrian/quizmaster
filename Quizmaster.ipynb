{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quizmaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import utils\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "def classify_questions():\n",
    "  labels = sorted(\n",
    "      ['science-technology', 'for-kids', 'video-games', 'sports', 'music'])\n",
    "\n",
    "  questions = pd.read_csv(\"data/train_dataset.csv\", header=None,\n",
    "                          encoding=\"iso-8859-1\", sep=\";\",names= ['id', 'question', 'answer', 'topic'])\n",
    "\n",
    "  REPLACE_BY_SPACE = re.compile('[/(){}\\[\\]|@,;]')\n",
    "  BAD_SYMBOLS = re.compile('[^0-9a-z #+_]')\n",
    "  STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "  def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_BY_SPACE.sub(' ', text)\n",
    "    text = BAD_SYMBOLS.sub(' ', text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = ' '.join(word for word in text.split() if\n",
    "                    word not in STOPWORDS)\n",
    "    return text\n",
    "\n",
    "  questions['question'] = questions['question'].apply(clean_text)\n",
    "  X = questions.question\n",
    "  y = questions.topic\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                      random_state=42)\n",
    "\n",
    "  # tokenizer\n",
    "  max_words = 2000\n",
    "  tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "  tokenize.fit_on_texts(X_train)\n",
    "  x_train = tokenize.texts_to_matrix(X_train)\n",
    "  x_test = tokenize.texts_to_matrix(X_test)\n",
    "\n",
    "  # Encoder\n",
    "  encoder = LabelEncoder()\n",
    "  encoder.fit(y_train)\n",
    "  y_train = encoder.transform(y_train)\n",
    "  y_test = encoder.transform(y_test)\n",
    "\n",
    "  num_classes = np.max(y_train) + 1\n",
    "  y_train = utils.to_categorical(y_train, num_classes)\n",
    "  y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "  batch_size = 64\n",
    "  epochs = 2\n",
    "\n",
    "  # Build the model\n",
    "  model = Sequential()\n",
    "  model.add(Dense(512, input_shape=(max_words,)))\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(num_classes))\n",
    "  model.add(Activation('softmax'))\n",
    "  model.compile(loss='categorical_crossentropy',\n",
    "                optimizer='adam',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            validation_data=(x_test,y_test))\n",
    "\n",
    "  val_score = model.evaluate(x_train, y_train,\n",
    "                             batch_size=batch_size, verbose=1)\n",
    "  score = model.evaluate(x_test, y_test,\n",
    "                         batch_size=batch_size, verbose=1)\n",
    "  print('Train acc:', val_score[1])\n",
    "  print('Test accuracy:', score[1])\n",
    "\n",
    "  # Classify topics\n",
    "  generated_questions = pd.read_csv(\"data/crowdanswers.tsv\",\n",
    "                                    encoding=\"utf-8\", delimiter=\"\\t\",\n",
    "                                    na_filter=False)\n",
    "  generated_questions.columns = ['id', 'question', 'answer', 'difficulty',\n",
    "                                 'opinion', 'factuality']\n",
    "\n",
    "  tokens = generated_questions['question'].apply(clean_text)\n",
    "\n",
    "  x_predict = tokenize.texts_to_matrix(tokens)\n",
    "  result = model.predict_classes(x_predict, batch_size=1)\n",
    "  predicted_labels = [labels[i] for i in result]\n",
    "  output = pd.DataFrame(data={\"id\": generated_questions[\"id\"],\n",
    "                              \"question\": generated_questions[\"question\"],\n",
    "                              \"answer\": generated_questions[\"answer\"],\n",
    "                              \"difficulty\": generated_questions[\"difficulty\"],\n",
    "                              \"opinion\": generated_questions[\"opinion\"],\n",
    "                              \"factuality\": generated_questions[\"factuality\"],\n",
    "                              \"topic\": predicted_labels})\n",
    "  output.to_csv('data/classified.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7130 samples, validate on 1783 samples\n",
      "Epoch 1/2\n",
      "7130/7130 [==============================] - 3s 415us/step - loss: 0.8370 - acc: 0.7129 - val_loss: 0.4257 - val_acc: 0.8906\n",
      "Epoch 2/2\n",
      "7130/7130 [==============================] - 2s 336us/step - loss: 0.2773 - acc: 0.9230 - val_loss: 0.3055 - val_acc: 0.9119\n",
      "7130/7130 [==============================] - 0s 59us/step\n",
      "1783/1783 [==============================] - 0s 64us/step\n",
      "Train acc: 0.9611500700259108\n",
      "Test accuracy: 0.9119461573915273\n"
     ]
    }
   ],
   "source": [
    "classify_questions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def get_class_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\", error_bad_lines=False)\n",
    "  questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  questions = questions.groupby(['question', 'topic'], as_index=False)[\n",
    "    'difficulty'].agg(majority)\n",
    "  return questions\n",
    "\n",
    "\n",
    "def get_class_question(difficulty, questions, topic):\n",
    "  return questions[\n",
    "    (questions.topic == topic) & (questions.difficulty == difficulty)]\n",
    "\n",
    "def classification(difficulty, topic):\n",
    "  questions = get_class_questions()\n",
    "  filtered_questions = get_class_question(difficulty, questions, topic)\n",
    "\n",
    "  for index, row in filtered_questions.iterrows():\n",
    "    print(row['question'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 rings' is a song by which American singer?\n",
      "How many strings does a violin have?\n",
      "In 1995, this company released its first console, which went on to dominate the industry.\n",
      "In which European city was Swedish pop group ABBA formed in 1972?\n",
      "This guy had a hit song called Papirsklip - \"Bent Mejding\"? \"Kim Larsen\"? \"Johnny Madsen\"? \"Jarl Friis Mikkelsen\"?'\n",
      "What Michael Jackson song had the first Music video on MTV?\n",
      "What city are the Beatles from?\n",
      "What city hosted the Beatles as the resident band at the Kaiserkeller and Top Ten Club?\n",
      "What instrument is primarily identified with rock and roll?\n",
      "What is Freddie Mercury's (lead singer of Queen) nationality?\n",
      "What is the Best-Selling Albums in History?\n",
      "What is the band containing the famous robotic duo called?\n",
      "What is the famous song called from the movie Titanic? \n",
      "What is the first name of Amadeus Mozart?\n",
      "What is the largest music festival in Budapest, Hungary called?\n",
      "What is the name of Dexter's annoying sister?\n",
      "What is the name of Lady Gaga's first hit single?\n",
      "What is the name of the stadium Queen performed at during Liva Aid?\n",
      "What kind of instrument is a violin?\n",
      "What singer holds the world record for most words in a hit single; Eminem, 50 Cent or Busta Rhymes?\n",
      "What was George Michaels first solo hit called?  \n",
      "What world famous heavy metal band was co-founded by its danish drummer, Lars Ulrich?\n",
      "What's the name of the most famous Italian plumber brothers?\n",
      "When was The Beatles formed?\n",
      "Where is the group abba from?\n",
      "Which American state is known to be a hub for country music?\n",
      "Which album of Linkin Park has the song \"Numb\"?\n",
      "Which country won the 2018 eurovision?\n",
      "Which year did Taylor Swift release the album \"Fearless\"\n",
      "Which year was black ops 1 released\n",
      "Who composed the classical piece Peter and the Wolf?\n",
      "Who is the latest official Disney princess?\n",
      "Who is the lead guitarist of Queen?\n",
      "Who is the lead singer of Metallica?\n",
      "Who is the original creator of GIT\n",
      "Who is the writer of the song \"Like a Rolling Stone\"?\n",
      "Who made the album Channel Orange?\n",
      "Who made the song \"Get low\" featured on the soundtrack of the videogame \"Need for Speed: Underground\"? - \"Ludacris\"? \"Lil Wayne\"? \"Lil John\"? \"Nate Dogg\"?' \n",
      "Who wrote the little match girl?\n"
     ]
    }
   ],
   "source": [
    "# Get Questions according to difficulty and topic\n",
    "classification(\"Medium\", \"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence / Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "answers = {\n",
    "  \"for-kids\": {\"false\": 0, \"true\": 0},\n",
    "  \"science-technology\": {\"false\": 0, \"true\": 0},\n",
    "  \"video-games\": {\"false\": 0, \"true\": 0},\n",
    "  \"music\": {\"false\": 0, \"true\": 0},\n",
    "  \"sports\": {\"false\": 0, \"true\": 0},\n",
    "}\n",
    "\n",
    "skipped = []\n",
    "\n",
    "#get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def get_answers():\n",
    "  return answers\n",
    "\n",
    "def get_next_question(g):\n",
    "  return g.sample(n=1, replace=True,\n",
    "           random_state=randint(0, 3000))\n",
    "\n",
    "def calc_threshold(threshold, n):\n",
    "  return np.mean(\n",
    "      [answers[n].get(\"false\"), answers[n].get(\"true\")]) < threshold\n",
    "\n",
    "# use answers from file + answers from classified data,since a few questions missing\n",
    "def give_answer(answer,generated_answer,user_answer,n):\n",
    "  false_answer2 = generated_answer.strip().lower() != user_answer.strip().lower()\n",
    "  false_answer = answer.strip().lower() != user_answer.strip().lower()\n",
    "  if (false_answer & false_answer2):\n",
    "    answers[n][\"false\"] = answers[n].get(\"false\") - 1\n",
    "  else:\n",
    "    answers[n][\"true\"] = answers[n].get(\"true\") + 1\n",
    "\n",
    "def get_conv_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  questions = questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  questions = questions.drop_duplicates(subset='question', keep=\"last\")\n",
    "  return questions.groupby(['topic'])\n",
    "\n",
    "\n",
    "def get_answers_to_questions():\n",
    "  answers_to_questions = pd.read_csv(\"data/question_answer.csv\",\n",
    "                                     encoding=\"utf-8\", sep=\";\")\n",
    "  answers_to_questions.columns = ['question', 'answer']\n",
    "  return answers_to_questions\n",
    "\n",
    "def get_question_answer(answers_to_questions, question):\n",
    "  return answers_to_questions[\n",
    "    answers_to_questions[\"question\"] == question][\n",
    "    \"answer\"].to_string(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def decision(probability=0.9):\n",
    "  return random.random() < probability\n",
    "\n",
    "def polymath_user(probability):\n",
    "  skipped = []\n",
    "  answers_to_questions = get_answers_to_questions()\n",
    "  questions = get_conv_questions()\n",
    "  not_finished = True\n",
    "  amount_of_questions = 0\n",
    "\n",
    "  while not_finished:\n",
    "    for n,g in questions:\n",
    "      if n not in skipped:\n",
    "        if calc_threshold(0, n):\n",
    "          skipped.append(n)\n",
    "          continue\n",
    "        question = get_next_question(g)\n",
    "        answer_generated = question[\"answer\"].to_string(index=False)\n",
    "        question_string = question.to_string(index=False)\n",
    "\n",
    "        answer = get_question_answer(answers_to_questions,question_string)\n",
    "        # hope for the best that the answers are right or available\n",
    "        if len(skipped) <= 4:\n",
    "          amount_of_questions += 1\n",
    "          if decision(probability):\n",
    "            if not answer_generated:\n",
    "              user_answer = answer\n",
    "              give_answer(answer, answer_generated, user_answer, n)\n",
    "            else:\n",
    "              user_answer = answer_generated\n",
    "              give_answer(answer, answer_generated, user_answer, n)\n",
    "          else:\n",
    "            give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        if len(skipped) == 4:\n",
    "          print(\"Amount of questions answered:\", amount_of_questions)\n",
    "          print(\"Finished topic was:\", n)\n",
    "          not_finished = False\n",
    "\n",
    "\n",
    "def topic_expert_user(probability, topic):\n",
    "  skipped = []\n",
    "  answers_to_questions = get_answers_to_questions()\n",
    "  questions = get_conv_questions()\n",
    "  not_finished = True\n",
    "  amount_of_questions = 0\n",
    "\n",
    "  while not_finished:\n",
    "    for n,g in questions:\n",
    "      if n not in skipped:\n",
    "        if calc_threshold(-1, n):\n",
    "          skipped.append(n)\n",
    "          continue\n",
    "        question = get_next_question(g)\n",
    "        answer_generated = question[\"answer\"].to_string(index=False)\n",
    "        question_string = question.to_string(index=False)\n",
    "\n",
    "        answer = get_question_answer(answers_to_questions,question_string)\n",
    "        # hope for the best that the answers are right or available\n",
    "        if n == topic:\n",
    "          if len(skipped) <= 4:\n",
    "            if decision(probability):\n",
    "              amount_of_questions +=1\n",
    "              if not answer_generated:\n",
    "                user_answer = answer\n",
    "                give_answer(answer, answer_generated, user_answer, n)\n",
    "              else:\n",
    "                user_answer = answer_generated\n",
    "                give_answer(answer, answer_generated, user_answer, n)\n",
    "            else:\n",
    "              give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        else:\n",
    "          give_answer(answer, answer_generated, \"False Answer\", n)\n",
    "        if len(skipped) == 4:\n",
    "          print(\"Amount of questions answered:\", amount_of_questions)\n",
    "          print(\"Finished Topic was:\", n)\n",
    "          not_finished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of questions answered: 19\n",
      "Finished topic was: science-technology\n",
      "Amount of questions answered: 0\n",
      "Finished Topic was: science-technology\n"
     ]
    }
   ],
   "source": [
    "## Can end up running quite long according to probabilty of answering questions right\n",
    "polymath_user(0.5)\n",
    "topic_expert_user(0.8, \"music\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Friend Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def takeCorrelation(elem):\n",
    "  return elem[1]\n",
    "\n",
    "STEMMER = nltk.stem.porter.PorterStemmer()\n",
    "\n",
    "def get_friends_questions():\n",
    "  return pd.read_csv(\"data/classified.csv\",\n",
    "                     encoding=\"utf-8\", sep=\",\")\n",
    "\n",
    "def stem_tokens(tokens, stemmer=STEMMER):\n",
    "  return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "  tokens = nltk.word_tokenize(text)\n",
    "  return stem_tokens(tokens)\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "  return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "\n",
    "def get_recommendations_feature(cutoff_k, questions, user_id):\n",
    "  print(\"Feature based recommendation\")\n",
    "  tfidf = TfidfVectorizer(tokenizer=tokenizer, stop_words='english')\n",
    "  tfs = tfidf.fit_transform(questions['question'])\n",
    "  # add column for vector\n",
    "  questions['tfsvector'] = list(tfs.toarray())\n",
    "  user_features = questions[questions['id'] == int(user_id)]['tfsvector'].mean()\n",
    "  # the questions which a user likes\n",
    "  questions = questions.groupby(['id'])\n",
    "  friends_questions = []\n",
    "  for n, g in questions:\n",
    "    g = g[g['opinion'] > 1]['tfsvector'].mean()\n",
    "    friends_questions.append((n, euclidean_distance(user_features, g)))\n",
    "  friends_questions.sort(key=takeCorrelation, reverse=True)\n",
    "  for friend in friends_questions[:int(cutoff_k)]:\n",
    "    print(friend)\n",
    "\n",
    "\n",
    "def get_recommendations_topic(cutoff_k, questions, user_id):\n",
    "  friends = []\n",
    "  print(\"Topic based recommendation:\")\n",
    "  user_features = questions[questions['id'] == int(user_id)].groupby(['topic'])[\n",
    "    'opinion'].mean()\n",
    "  questions = questions.groupby(['id'])\n",
    "  for n, g in questions:\n",
    "    if n == int(user_id):\n",
    "      continue\n",
    "    # when classification not works properly then some users have only 4 topics\n",
    "    if len(g.groupby(['topic'])['opinion'].mean()) < 5:\n",
    "      continue\n",
    "    corr, p_value = pearsonr(user_features,\n",
    "                             g.groupby(['topic'])['opinion'].mean())\n",
    "    friends.append((n, corr))\n",
    "  friends.sort(key=takeCorrelation, reverse=True)\n",
    "  for friend in friends[:int(cutoff_k)]:\n",
    "    print(friend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature based recommendation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 0.36076689057979405)\n",
      "(11, 0.3386440771631049)\n",
      "(27, 0.3282917165082846)\n",
      "(24, 0.30563175815672294)\n",
      "(31, 0.297454486813683)\n"
     ]
    }
   ],
   "source": [
    "# cutoff, questions, user_id\n",
    "get_recommendations_feature(5,get_friends_questions(),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic based recommendation:\n",
      "(18, 0.9777715853271727)\n",
      "(34, 0.9195235405587819)\n",
      "(11, 0.9146789084322638)\n",
      "(36, 0.913861921714508)\n",
      "(12, 0.7790063508395929)\n"
     ]
    }
   ],
   "source": [
    "# cutoff, questions, user_id\n",
    "get_recommendations_topic(5,get_friends_questions(),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Preference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users_questions():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  return questions\n",
    "\n",
    "def get_preferance_id(questions, userid):\n",
    "  user_questions = questions[questions['id'] == int(userid)]\n",
    "  return user_questions\n",
    "\n",
    "\n",
    "def get_prefereance_filtered_qustions(questions, user_preferance):\n",
    "  questions = questions[questions['topic'] == user_preferance].head(10)\n",
    "  return questions\n",
    "\n",
    "\n",
    "def get_user_preferance(user_questions):\n",
    "  user_questions = user_questions.groupby('topic')['opinion'].mean()\n",
    "  user_preferance = user_questions.idxmax()\n",
    "  return user_preferance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>opinion</th>\n",
       "      <th>factuality</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>For which song did Toy Story get nominated to ...</td>\n",
       "      <td>We belong together</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>At what age did Jimmy Hendrix, Janis Joplin an...</td>\n",
       "      <td>27</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>What's the name of the most famous Italian plu...</td>\n",
       "      <td>Mario and Luigi</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>What was the Beatles biggest selling single?</td>\n",
       "      <td>She Loves you</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>What was George Michaels first solo hit called?</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>In which decade was Dolly Parton born?</td>\n",
       "      <td>1940's</td>\n",
       "      <td>Hard</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0</td>\n",
       "      <td>Which famous Disney movie features a song call...</td>\n",
       "      <td>Lion King</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>What is the name of the toy cowboy in Toy Story?</td>\n",
       "      <td>Woody</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>Freddie Mercury was the lead vocalist of which...</td>\n",
       "      <td>Queen</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>7 rings' is a song by which American singer?</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>Easy</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           question              answer  \\\n",
       "9    0  For which song did Toy Story get nominated to ...  We belong together   \n",
       "10   0  At what age did Jimmy Hendrix, Janis Joplin an...                  27   \n",
       "12   0  What's the name of the most famous Italian plu...     Mario and Luigi   \n",
       "24   0       What was the Beatles biggest selling single?       She Loves you   \n",
       "25   0  What was George Michaels first solo hit called?      Careless Whisper   \n",
       "26   0             In which decade was Dolly Parton born?              1940's   \n",
       "37   0  Which famous Disney movie features a song call...           Lion King   \n",
       "38   0   What is the name of the toy cowboy in Toy Story?               Woody   \n",
       "39   0  Freddie Mercury was the lead vocalist of which...               Queen   \n",
       "40   0       7 rings' is a song by which American singer?       Ariana Grande   \n",
       "\n",
       "   difficulty  opinion  factuality  topic  \n",
       "9        Hard        3           0  music  \n",
       "10       Easy        3           0  music  \n",
       "12       Easy        3           0  music  \n",
       "24     Medium        3           0  music  \n",
       "25     Medium        3           0  music  \n",
       "26       Hard        3           0  music  \n",
       "37       Easy        3           0  music  \n",
       "38       Easy        3           0  music  \n",
       "39       Easy        3           0  music  \n",
       "40       Easy        3           0  music  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get favourite Topic according to user_id\n",
    "user_questions = get_preferance_id(get_users_questions(),5)\n",
    "user_preferance = get_user_preferance(user_questions)\n",
    "get_prefereance_filtered_qustions(get_users_questions(),user_preferance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difficulty / Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "answered = {\"Easy\": False, \"Medium\": False, \"Hard\": False}\n",
    "\n",
    "# get most common item, in case of tie the first\n",
    "def majority(lst):\n",
    "  data = Counter(lst)\n",
    "  return max(lst, key=data.get)\n",
    "\n",
    "def prepare_diff():\n",
    "  questions = pd.read_csv(\"data/classified.csv\",\n",
    "                          encoding=\"utf-8\", sep=\",\")\n",
    "  answers_to_questions = pd.read_csv(\"data/question_answer.csv\",\n",
    "                                     encoding=\"utf-8\", sep=\";\")\n",
    "  answers_to_questions.columns = ['question', 'answer']\n",
    "  questions = questions.groupby('question').filter(\n",
    "      lambda x: x['factuality'].sum() < 1)\n",
    "  grouped_questions = questions.groupby(['question', 'topic'], as_index=False)[\n",
    "    'difficulty'].agg(majority)\n",
    "  questions = questions.drop_duplicates(subset='question', keep=\"last\")\n",
    "  return answers_to_questions, grouped_questions, questions\n",
    "\n",
    "\n",
    "def sample_question(questions_to_answer):\n",
    "  return questions_to_answer.sample(n=1, replace=True,\n",
    "                                    random_state=randint(0, 10000))\n",
    "\n",
    "\n",
    "def check_answer(answer, answered, generated_answer, user_answer):\n",
    "  true_answer2 = generated_answer.strip().lower() == user_answer.strip().lower()\n",
    "  true_answer = answer.strip().lower() == user_answer.strip().lower()\n",
    "  if (true_answer) or (true_answer2):\n",
    "    if answered[\"Medium\"] == True:\n",
    "      answered[\"Hard\"] = True\n",
    "    if answered[\"Easy\"] == True:\n",
    "      answered[\"Medium\"] = True\n",
    "    if answered[\"Easy\"] == False:\n",
    "      answered[\"Easy\"] = True\n",
    "\n",
    "\n",
    "def get_answers_to_questions_diff(answers_to_questions, question):\n",
    "  return answers_to_questions[\n",
    "    answers_to_questions[\"question\"] == question][\n",
    "    \"answer\"].to_string(index=False)\n",
    "\n",
    "\n",
    "def get_answered_diff():\n",
    "  return answered\n",
    "\n",
    "\n",
    "def get_questions_to_answer(answered, questions):\n",
    "  questions_to_answer = questions[questions['difficulty'] == \"Easy\"]\n",
    "  if answered[\"Easy\"] == True:\n",
    "    questions_to_answer = questions[questions['difficulty'] == \"Medium\"]\n",
    "  if answered[\"Medium\"] == True:\n",
    "    questions_to_answer = questions[questions['difficulty'] == \"Hard\"]\n",
    "  return questions_to_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffuculty_user(probability):\n",
    "  answers_to_questions, grouped_questions, questions = prepare_diff()\n",
    "\n",
    "  answered = get_answered_diff()\n",
    "\n",
    "  not_finished = True\n",
    "\n",
    "  while not_finished:\n",
    "    questions_to_answer = get_questions_to_answer(answered, grouped_questions)\n",
    "\n",
    "    random_topic_question = sample_question(questions_to_answer)\n",
    "\n",
    "    print(\"Difficulty:\", random_topic_question[\"difficulty\"].to_string(index=False))\n",
    "    question = random_topic_question[\"question\"].to_string(index=False)\n",
    "\n",
    "\n",
    "    generated_answer = questions[questions['question'] == question]['answer'].to_string(index=False)\n",
    "\n",
    "    answer = get_answers_to_questions_diff(answers_to_questions, question)\n",
    "\n",
    "    print(question)\n",
    "    if decision(probability):\n",
    "      if not generated_answer:\n",
    "        user_answer = answer\n",
    "        check_answer(answer, answered, generated_answer, user_answer)\n",
    "      else:\n",
    "        user_answer = generated_answer\n",
    "        check_answer(answer, answered, generated_answer, user_answer)\n",
    "    else:\n",
    "      check_answer(answer, answered, generated_answer, \"Wrong!!!\")\n",
    "    answered = get_answered_diff()\n",
    "    if answered[\"Hard\"] == True:\n",
    "      print(\"Finished arrived at hard questions\")\n",
    "      not_finished = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difficulty: Easy\n",
      "What is a baby dog called?\n",
      "Difficulty: Medium\n",
      "Who invented the telephone?\n",
      "Difficulty: Medium\n",
      "Who is the latest official Disney princess?\n",
      "Difficulty: Hard\n",
      "Which console has sold the most\n",
      "Difficulty: Hard\n",
      "In which year did IT Act came into force in In...\n",
      "Difficulty: Hard\n",
      "Who won the Turing award in 2005\n",
      "Difficulty: Hard\n",
      "What is the name of the purple Teletubby?\n",
      "Finished arrived at hard questions\n"
     ]
    }
   ],
   "source": [
    "# Probability of answering a question right\n",
    "diffuculty_user(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
