{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/silvan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "questions = pd.read_csv(\"data/train_dataset.csv\", header=None, encoding=\"iso-8859-1\", sep=\";\")\n",
    "questions.columns = ['id', 'question', 'answer', 'topic']\n",
    "\n",
    "\n",
    "\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "questions['question'] = questions['question'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6417 samples, validate on 713 samples\n",
      "Epoch 1/2\n",
      "6417/6417 [==============================] - 8s 1ms/step - loss: 0.8006 - acc: 0.7201 - val_loss: 0.4133 - val_acc: 0.8710\n",
      "Epoch 2/2\n",
      "6417/6417 [==============================] - 2s 328us/step - loss: 0.3344 - acc: 0.9024 - val_loss: 0.3407 - val_acc: 0.8892\n",
      "7130/7130 [==============================] - 1s 72us/step\n",
      "1783/1783 [==============================] - 0s 80us/step\n",
      "Train acc: 0.9357643758932972\n",
      "Test accuracy: 0.8844643860002348\n"
     ]
    }
   ],
   "source": [
    "X = questions.question\n",
    "y = questions.topic\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "train_posts = X_train\n",
    "train_tags = y_train\n",
    "\n",
    "test_posts = X_test\n",
    "test_tags = y_test\n",
    "\n",
    "max_words = 1000\n",
    "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
    "\n",
    "tokenize.fit_on_texts(train_posts) # only fit on train\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)\n",
    "\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "y_train = utils.to_categorical(y_train, num_classes)\n",
    "y_test = utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)\n",
    "\n",
    "\n",
    "val_score = model.evaluate(x_train, y_train,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "print('Train acc:',val_score[1] )\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_questions = pd.read_csv(\"data/crowdanswers.tsv\", encoding=\"ISO-8859-1\", delimiter=\"\\t\", na_filter=False)\n",
    "generated_questions.columns = ['id', 'question', 'answer', 'difficulty', 'opinion', 'factuality']\n",
    "\n",
    "labels = sorted(['science-technology', 'for-kids', 'video-games', 'sports', 'music'])\n",
    "\n",
    "generated_questions['question'].apply(clean_text)\n",
    "x_predict = tokenize.texts_to_matrix(generated_questions['question'])\n",
    "# result = model.predict(x_predict)\n",
    "result= model.predict_classes(x_predict, batch_size=1)\n",
    "#y_classes = result.argmax(axis=-1)\n",
    "predictated_labels = [labels[i] for i in result]\n",
    "# predicted_label = sorted(labels)[result]\n",
    "output = pd.DataFrame(data={\"id\":generated_questions[\"id\"], \"question\":generated_questions[\"question\"], \"answer\":generated_questions[\"answer\"], \"difficulty\":generated_questions[\"difficulty\"], \"opinion\":generated_questions[\"opinion\"], \"factuality\":generated_questions[\"factuality\"], \"topic\":predictated_labels})\n",
    "output.to_csv('generated.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.models import Sequential, load_model\n",
    "from tensorflow.python.keras.layers import Dense, Embedding, Dropout, Flatten, Activation\n",
    "from tensorflow.python.keras.layers import LSTM, SimpleRNN\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.preprocessing import text as keras_text, sequence as keras_seq\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import set_random_seed\n",
    "import gc\n",
    "import os\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "EMBEDDING_SIZE=300\n",
    "WORDS_SIZE=8000\n",
    "INPUT_SIZE=100\n",
    "NUM_CLASSES=5\n",
    "EPOCHS=10\n",
    "\n",
    "questions = pd.read_csv(\"data/train_dataset.csv\", header=None, encoding=\"iso-8859-1\", sep=\";\")\n",
    "questions.columns = ['id', 'question', 'answer', 'topic']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
    "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
    "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
    "    return text\n",
    "\n",
    "questions['question'] = questions['question'].apply(clean_text)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)\n",
    "\n",
    "\n",
    "tokenizer = keras_text.Tokenizer(char_level=False)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "tokenizer.num_words=WORDS_SIZE\n",
    "\n",
    "maxlen = 100\n",
    "## Tokkenizing train data and create matrix\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_train = pad_sequences(list_tokenized_train, padding='post', maxlen=maxlen)\n",
    "\n",
    "## Tokkenizing test data and create matrix\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "x_test = pad_sequences(list_tokenized_test, padding='post', maxlen=maxlen)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "\n",
    "y_train = utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = utils.to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('word2vec/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "vocabulary_size=min(len(word_index)+1,8000)\n",
    "embedding_matrix = np.zeros((vocabulary_size, EMBEDDING_SIZE))\n",
    "for word, i in word_index.items():\n",
    "    if i>=WORDS_SIZE:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = word2vec[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError:\n",
    "        embedding_matrix[i]=np.random.normal(0,np.sqrt(0.25),EMBEDDING_SIZE)\n",
    "\n",
    "embedding_layer = Embedding(vocabulary_size,\n",
    "                            EMBEDDING_SIZE,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=INPUT_SIZE,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name='Word2Vec LSTM')\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(EMBEDDING_SIZE))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7130 samples, validate on 1783 samples\n",
      "Epoch 1/10\n",
      "7130/7130 [==============================] - 92s 13ms/sample - loss: 1.4573 - categorical_accuracy: 0.3544 - val_loss: 1.3593 - val_categorical_accuracy: 0.4173\n",
      "Epoch 2/10\n",
      "7130/7130 [==============================] - 90s 13ms/sample - loss: 1.3861 - categorical_accuracy: 0.4107 - val_loss: 1.3569 - val_categorical_accuracy: 0.4173\n",
      "Epoch 3/10\n",
      "7130/7130 [==============================] - 99s 14ms/sample - loss: 1.3838 - categorical_accuracy: 0.4116 - val_loss: 1.3576 - val_categorical_accuracy: 0.4173\n",
      "Epoch 4/10\n",
      "4608/7130 [==================>...........] - ETA: 35s - loss: 1.3760 - categorical_accuracy: 0.4160"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = x_train,\n",
    "          y = y_train,\n",
    "          validation_data = (x_test, y_test),\n",
    "          epochs = EPOCHS,\n",
    "          batch_size = 128,\n",
    "          verbose =1)\n",
    "\n",
    "\n",
    "val_score = model.evaluate(x_train, y_train, batch_size=batch_size, verbose=1)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music', 'music']\n"
     ]
    }
   ],
   "source": [
    "generated_questions = pd.read_csv(\"data/crowdanswers.tsv\", encoding=\"ISO-8859-1\", delimiter=\"\\t\", na_filter=False)\n",
    "generated_questions.columns = ['id', 'question', 'answer', 'difficulty', 'opinion', 'factuality']\n",
    "\n",
    "labels = sorted(['science-technology', 'for-kids', 'video-games', 'sports', 'music'])\n",
    "\n",
    "list_tokenized = tokenizer.texts_to_sequences(generated_questions['question'])\n",
    "x_predict = pad_sequences(list_tokenized, padding='post', maxlen=maxlen)\n",
    "\n",
    "result= model.predict_classes(x_predict, batch_size=128)\n",
    "predictated_labels = [labels[i] for i in result]\n",
    "print(predictated_labels)\n",
    "# predicted_label = sorted(labels)[result]\n",
    "output = pd.DataFrame(data={\"id\":generated_questions[\"id\"], \"question\":generated_questions[\"question\"], \"answer\":generated_questions[\"answer\"], \"difficulty\":generated_questions[\"difficulty\"], \"opinion\":generated_questions[\"opinion\"], \"factuality\":generated_questions[\"factuality\"], \"topic\":predictated_labels})\n",
    "output.to_csv('generated.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
